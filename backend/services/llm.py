import google.generativeai as genai
from google.generativeai.types import GenerationConfig
import json
import re
import os
import platform
from typing import List

from config import settings
from models.services import NOTION_BLOCKS_SCHEMA

# åˆå§‹åŒ– Gemini
# Removed global init

# å®šç¾© Notion Blocks çš„ JSON Schema
# Moved to models.services.schemas.NOTION_BLOCKS_SCHEMA


def normalize_path(path: str) -> str:
    """
    å°‡è·¯å¾‘çµ±ä¸€è½‰æ›ç‚ºç•¶å‰ç³»çµ±å¯è­˜åˆ¥çš„æ ¼å¼

    è™•ç†æƒ…æ³ï¼š
    1. WSL ç’°å¢ƒæ”¶åˆ° Windows è·¯å¾‘ (C:\\...) â†’ è½‰æ›ç‚º /mnt/c/...
    2. Windows ç’°å¢ƒæ”¶åˆ° Unix è·¯å¾‘ (/mnt/c/...) â†’ è½‰æ›ç‚º C:\\...
    3. å·²ç¶“æ˜¯æ­£ç¢ºæ ¼å¼ â†’ ç›´æ¥è¿”å›

    Args:
        path: ä»»æ„æ ¼å¼çš„æ–‡ä»¶è·¯å¾‘

    Returns:
        ç•¶å‰ç³»çµ±å¯è­˜åˆ¥çš„æ¨™æº–è·¯å¾‘
    """
    # æª¢æ¸¬æ˜¯å¦åœ¨ WSL ç’°å¢ƒ
    is_wsl = "microsoft" in platform.uname().release.lower()

    if is_wsl:
        # WSL ç’°å¢ƒï¼šå°‡ Windows è·¯å¾‘è½‰æ›ç‚º Unix è·¯å¾‘
        if path.startswith(("C:\\", "c:\\")):
            # C:\Users\... â†’ /mnt/c/Users/...
            unix_path = path.replace("C:\\", "/mnt/c/").replace("c:\\", "/mnt/c/")
            unix_path = unix_path.replace("\\", "/")
            return unix_path
        elif path.startswith(("D:\\", "d:\\")):
            # D:\... â†’ /mnt/d/...
            unix_path = path.replace("D:\\", "/mnt/d/").replace("d:\\", "/mnt/d/")
            unix_path = unix_path.replace("\\", "/")
            return unix_path
    else:
        # Windows ç’°å¢ƒï¼šå°‡ Unix è·¯å¾‘è½‰æ›ç‚º Windows è·¯å¾‘
        if path.startswith("/mnt/c/"):
            # /mnt/c/Users/... â†’ C:\Users\...
            return path.replace("/mnt/c/", "C:\\").replace("/", "\\")
        elif path.startswith("/mnt/d/"):
            return path.replace("/mnt/d/", "D:\\").replace("/", "\\")

    # å·²ç¶“æ˜¯æ­£ç¢ºæ ¼å¼æˆ–å…¶ä»–æƒ…æ³
    return path




async def get_static_options_menu(
    file_paths: List[str], 
    filenames: List[str] = None,
    api_key: str = None
) -> dict:
    """
    ä¸èª¿ç”¨ LLMï¼Œç›´æ¥è¿”å›éœæ…‹çš„é¸é …é¸å–®
    ç”¨æ–¼åˆå§‹ä¸Šå‚³å¾Œï¼Œè®“ä½¿ç”¨è€…é¸æ“‡åˆ†ææ–¹å‘
    """
    # é€™è£¡æˆ‘å€‘ä¾ç„¶å¯ä»¥å…ˆå°‡æª”æ¡ˆä¸Šå‚³åˆ° Gemini (å¦‚æœ refine_summary éœ€è¦ä¾è³´å·²ä¸Šå‚³çš„æª”æ¡ˆ)
    # ä½†è€ƒæ…®åˆ° refine_summary ä¹Ÿå¯ä»¥è‡ªå·±è™•ç†ä¸Šå‚³ï¼Œé€™è£¡æˆ‘å€‘å…ˆè·³éä¸Šå‚³ï¼Œåªè¿”å›éœæ…‹å…§å®¹
    # ç‚ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œtitle ä½¿ç”¨æª”å
    
    title = filenames[0] if filenames else "è«–æ–‡ç­†è¨˜"
    
    # å»ºæ§‹éœæ…‹çš„ Notion Blocks (å°æ‡‰åŸæœ¬ Prompt çš„é¸é …)
    blocks = [
        {
            "object": "block",
            "type": "heading_2",
            "heading_2": {
                "rich_text": [{"type": "text", "text": {"content": "è«‹é¸æ“‡åˆ†ææ–¹å‘"}}]
            }
        },
        {
            "object": "block",
            "type": "paragraph",
            "paragraph": {
                "rich_text": [{"type": "text", "text": {"content": "è«‹å¾ä¸‹æ–¹ã€Œå¿«é€ŸæŒ‡ä»¤ã€æˆ–ç›´æ¥è¼¸å…¥éœ€æ±‚ä¾†é–‹å§‹åˆ†æï¼š"}}]
            }
        },
        {
            "object": "block",
            "type": "bulleted_list_item",
            "bulleted_list_item": {
                "rich_text": [{"type": "text", "text": {"content": "**é¸é … A - å¿«é€Ÿæ‘˜è¦æŒ‡ä»¤**ï¼šç”Ÿæˆ500å­—æ‘˜è¦ï¼ŒåŒ…å«ç›®çš„ã€æ–¹æ³•ã€çµæœèˆ‡çµè«–ã€‚"}}]
            }
        },
        {
            "object": "block",
            "type": "bulleted_list_item",
            "bulleted_list_item": {
                "rich_text": [{"type": "text", "text": {"content": "**é¸é … B - è«–æ–‡çµæ§‹è§£ææŒ‡ä»¤**ï¼šè§£ææ‘˜è¦ã€å¼•è¨€ã€æ–¹æ³•ã€çµæœèˆ‡è¨è«–ã€‚"}}]
            }
        },
        {
            "object": "block",
            "type": "bulleted_list_item",
            "bulleted_list_item": {
                "rich_text": [{"type": "text", "text": {"content": "**é¸é … C - æ·±å…¥æŠ€è¡“æˆ–ç†è«–è§£ææŒ‡ä»¤**ï¼šè©³ç´°è§£é‡‹æŠ€è¡“æ¦‚å¿µèˆ‡åŸç†ã€‚"}}]
            }
        },
        {
            "object": "block",
            "type": "bulleted_list_item",
            "bulleted_list_item": {
                "rich_text": [{"type": "text", "text": {"content": "**é¸é … D - æ‰¹åˆ¤æ€§åˆ†ææŒ‡ä»¤**ï¼šåˆ†æç ”ç©¶å„ªç¼ºé»ã€è³‡æ–™åˆç†æ€§èˆ‡æ½›åœ¨é™åˆ¶ã€‚"}}]
            }
        }
    ]

    return {
        "title": title,
        "blocks": blocks,
        "is_initial_menu": True
    }


async def refine_summary(
    original_summary: dict, 
    user_feedback: str,
    api_key: str = None
) -> dict:
    """
    æ ¹æ“šç”¨æˆ¶åé¥‹èª¿æ•´ç­†è¨˜å…§å®¹
    
    Args:
        original_summary: åŸå§‹ç­†è¨˜å…§å®¹ (åŒ…å« title, blocks, temp_paths)
        user_feedback: ç”¨æˆ¶çš„èª¿æ•´éœ€æ±‚
        api_key: Gemini API Key
        
    Returns:
        æ›´æ–°å¾Œçš„ç­†è¨˜å…§å®¹
    """
    try:
        if not api_key:
            raise ValueError("Gemini API Key is required")
            
        genai.configure(api_key=api_key)
            
        print(f"[GEMINI API] Refining summary with feedback: {user_feedback}")

        # 1. å˜—è©¦å¾åŸå§‹æ‘˜è¦ä¸­ç²å–æ–‡ä»¶è·¯å¾‘
        temp_paths = original_summary.get("temp_paths", [])
        uploaded_files = []

        if temp_paths:
            # è¦ç¯„åŒ–è·¯å¾‘ï¼ˆè™•ç† Windows/Unix æ ¼å¼å·®ç•°ï¼‰
            normalized_paths = [normalize_path(path) for path in temp_paths]

            # éæ¿¾å­˜åœ¨çš„æ–‡ä»¶ä¸¦ä¸Šå‚³
            valid_paths = [path for path in normalized_paths if os.path.exists(path)]

            if valid_paths:
                uploaded_files = [genai.upload_file(path=path) for path in valid_paths]
                print(f"[GEMINI API] Uploaded {len(uploaded_files)} file(s) to Gemini.")
            else:
                print(f"[GEMINI API] Warning: No valid files found from {len(temp_paths)} path(s).")
        else:
            print("[GEMINI API] Warning: No temp_paths in original_summary.")
        
        # å°‡åŸå§‹ blocks è½‰ç‚º JSON å­—ä¸²ä»¥ä¾¿æ”¾å…¥ Prompt
        # ç‚ºäº†ç¯€çœ tokenï¼Œæˆ‘å€‘éæ¿¾æ‰æŠ€è¡“æ€§çš„æ¬„ä½ (å¦‚ temp_paths, pdf_urls)ï¼Œ
        # ä½†ä¿ç•™ title, blocks (ç­†è¨˜æœ¬é«”) å’Œ files (æª”å)ï¼Œè®“ LLM çŸ¥é“å…§å®¹èˆ‡ä¾†æºã€‚
        context_summary = {
            "title": original_summary.get("title"),
            "blocks": original_summary.get("blocks"),
            "files": original_summary.get("files", [])
        }
        original_json = json.dumps(context_summary, ensure_ascii=False, indent=2)
        
        prompt = (
            "# Role Definition\n"
            "ä½ æ˜¯ä¸€ä½è«–æ–‡ç†è§£å°ˆå®¶ã€‚å­¸ç”Ÿä¹‹å‰ä¸Šå‚³äº†è«–æ–‡ï¼Œç¾åœ¨æå‡ºäº†æ–°çš„éœ€æ±‚æˆ–ä¿®æ”¹å»ºè­°ã€‚\n"
            "ä½ çš„ä»»å‹™æ˜¯ï¼š**åƒè€ƒåŸå§‹è«–æ–‡ PDF** ä»¥åŠ **èˆŠçš„ç­†è¨˜**ï¼Œæ ¹æ“šå­¸ç”Ÿçš„åé¥‹ä¾†è™•ç†ã€‚\n\n"

            "# User Feedback (å­¸ç”Ÿåé¥‹)\n"
            f"{user_feedback}\n\n"

            "# Original Summary (åŸå§‹ç­†è¨˜)\n"
            f"{original_json}\n\n"

            "# Instructions\n"
            "**0. é—œæ–¼ã€ŒåŸå§‹ç­†è¨˜ã€çš„è™•ç†åŸå‰‡ï¼ˆæœ€é‡è¦ï¼ï¼‰**ï¼š\n"
            "   - **çµ•å°ä¿ç•™**ï¼šé™¤éå­¸ç”Ÿæ˜ç¢ºè¦æ±‚ã€Œåˆªé™¤ã€æŸéƒ¨åˆ†ï¼Œå¦å‰‡ **å¿…é ˆä¿ç•™åŸå§‹ç­†è¨˜ä¸­çš„æ‰€æœ‰å…§å®¹**ã€‚\n"
            "   - **æ–°å¢æ¨¡å¼**ï¼šå°æ–¼è£œå……èªªæ˜ã€æ·±å…¥è§£æç­‰éœ€æ±‚ï¼Œè«‹å°‡æ–°ç”Ÿæˆçš„å…§å®¹ **é™„åŠ ** åˆ°åŸå§‹ç­†è¨˜çš„ç›¸é—œæ®µè½ä¹‹å¾Œï¼Œæˆ–è€…æ˜¯æ–°å¢ä¸€å€‹æ¨™é¡Œå€å¡Šä¾†æ”¾ç½®ã€‚\n"
            "   - **ç¦æ­¢è¦†è“‹**ï¼šä¸è¦å› ç‚ºç”Ÿæˆäº†æ–°å…§å®¹å°±ä¸Ÿæ£„äº†èˆŠå…§å®¹ã€‚ä½ çš„è¼¸å‡ºå¿…é ˆåŒ…å«ã€ŒèˆŠçš„å®Œæ•´å…§å®¹ã€+ã€Œæ–°çš„è£œå……å…§å®¹ã€ã€‚\n\n"

            "**1. é¸é …åŸ·è¡Œå„ªå…ˆ**ï¼š\n"
            "   - å¦‚æœå­¸ç”Ÿåé¥‹åŒ…å«ã€Œé¸é … Aã€~ã€Œé¸é … Eã€ï¼Œé€™è¦–ç‚ºå…¨æ–°çš„åˆ†æè«‹æ±‚ã€‚æ­¤æ™‚ï¼ˆä¹Ÿåªæœ‰æ­¤æ™‚ï¼‰å¯ä»¥å¿½ç•¥åŸå§‹ç­†è¨˜ï¼Œé‡æ–°ç”Ÿæˆå…¨æ–°çš„å®Œæ•´çµæ§‹ã€‚\n\n"

            "**2. ä¸€èˆ¬èª¿æ•´ï¼ˆéé¸é …æŒ‡ä»¤ï¼‰**ï¼š\n"
            "   - å‹™å¿…é–±è®€é™„å¸¶çš„ PDF æ–‡ä»¶ä¾†ç²å–æ­£ç¢ºè³‡è¨Šã€‚\n"
            "   - å°‡æ–°è³‡è¨Šæ•´åˆé€²ç¾æœ‰çµæ§‹ï¼Œä¿æŒç­†è¨˜çš„å®Œæ•´æ€§ã€‚\n\n"

            "**3. æ ¼å¼è¦ç¯„**ï¼š\n"
            "   - Text content ä¸­çµ•å°ä¸è¦ä½¿ç”¨ Markdown èªæ³•ï¼ˆå¦‚ `**`ï¼‰ï¼Œå¿…é ˆä½¿ç”¨ annotationsã€‚\n"
            "   - Text content é–‹é ­çµ•å°ä¸è¦åŒ…å« `â€¢`ã€`-` ç­‰åˆ—è¡¨ç¬¦è™Ÿã€‚\n"
            "   - **åš´æ ¼ç¦æ­¢ä½¿ç”¨ä»»ä½• Emoji ç¬¦è™Ÿ**ï¼ˆå¦‚ ğŸ’¡ã€ğŸ“Šã€âœ… ç­‰ï¼‰ï¼Œè«‹ç”¨ç´”æ–‡å­—æ›¿ä»£ã€‚\n\n"

            "# Output Context\n"
            "è«‹ç›´æ¥è¼¸å‡ºä¿®æ”¹å¾Œçš„ **å®Œæ•´** JSONï¼ˆåŒ…å«æ‰€æœ‰ä¿ç•™çš„èˆŠå€å¡Šå’Œæ–°ç”Ÿæˆçš„å€å¡Šï¼‰ã€‚"
        )
        
        # é…ç½®çµæ§‹åŒ–è¼¸å‡º
        generation_config = GenerationConfig(
            response_mime_type="application/json",
            response_schema=NOTION_BLOCKS_SCHEMA
        )
        
        model = genai.GenerativeModel(
            model_name=settings.GEMINI_MODEL_NAME,
            generation_config=generation_config
        )
        
        # å°‡ prompt å’Œ ä¸Šå‚³çš„æ–‡ä»¶ä¸€èµ·å‚³çµ¦ Gemini
        # request_content é †åº: [Prompt, File1, File2, ...]
        request_content = [prompt]
        if uploaded_files:
            request_content.extend(uploaded_files)

        # ä½¿ç”¨ generate_content
        response = await model.generate_content_async(request_content)
        
        # è§£æçµæœ
        result = json.loads(response.text)
        
        print(f"[GEMINI API] Success: Refined summary based on feedback.")
        return {
            "title": result.get("title", original_summary.get("title")),
            "blocks": result.get("blocks", []),
            # ä¿ç•™ temp_paths ä»¥ä¾¿ä¸‹æ¬¡ç¹¼çºŒä¿®æ”¹
            "temp_paths": temp_paths,
            "is_initial_menu": False
        }
        
    except Exception as e:
        print(f"[GEMINI API] Failed to refine summary: {e}")
        raise RuntimeError(f"Failed to refine summary: {e}")
